<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>llm-ai</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="policies.css" />
</head>
<body>
<h1 id="large-language-models-ai">Large Language Models (AI)</h1>
<h2 id="philosophical-approach">Philosophical Approach</h2>
<p>What you refer to as ‘AI’ is more specifically a Large Language Model
or LLM: essentially, these systems are trained on vast corpora of
human-produced text to identify statistical patterns in language. LLMs
can generate remarkably coherent responses to queries, though they don’t
truly ‘understand’ content the way humans do. This potent technology is
transforming every field, and history is no exception.</p>
<p>In history classes of yore (i.e., just several years ago), many
collegiate history classes would have featured tasks such as assembling
a literature review, writing an analytical essay, or deriving insights
from a primary source. Because these tasks are all closely related to
textual corpora, LLMs are quite good at them, which means we as
historians now have a powerful new tool at our disposal — which you will
make use of in this course.</p>
<p>Especially in the short term, this scale of change is threatening,
and creates new challenges of intellectual honesty and course policies:
How do we differentiate between your intellectual labor and that of the
LLM? What is the point of artificially separating you from a tool that
you will have in the “real world”? These questions have forced humanists
and social scientists (historians are both) to reconsider what is at the
core of the field: a critical assessment of what constitutes historical
evidence, and making sense of that evidence through analytical
reasoning. AI shifts the focus away from the <em>products</em> of these
pursuits and toward <em>research skills</em> and <em>habits of
mind</em>: the fact that a machine can now competently produce an
analytical essay with no grammatical errors and based on primary sources
makes an ability to critically evaluate those products more important
than ever.</p>
<h3 id="llm-policies">LLM Policies</h3>
<p>This course embraces the “broad use” level of AI <a
href="https://teaching.pitt.edu/resources/teaching-with-generative-ai/">policy
specified by the Center for Teaching and Learning</a>:</p>
<blockquote>
<p>The use of Generative AI tools, including ChatGPT, is
encouraged/permitted in this course for students who wish to use them.
You may choose to use AI tools to help brainstorm assignments or
projects or to revise existing work you have written. However, to adhere
to scholarly values, students must cite any AI-generated material that
informed their work (this includes in-text citations and/or use of
quotations, and in your reference list). Using an AI tool to generate
content without proper attribution qualifies as academic dishonesty.</p>
</blockquote>
<p>In practice, however, these guidelines are more difficult to follow
than it may seem at first because there is such a broad spectrum of AI
usage. What if you write your own essay, but ask an LLM to improve the
formatting and check it for sentence clarity and spelling errors? Does
that require acknowledgement? What if you asked the LLM to identify the
“most important” sections of a primary source?</p>
<p>There are no easy answers to these questions, and expectations will
vary widely between courses. In this class, I take it for granted that
you will use LLMs to assist with tasks such as formatting, grammatical /
syntactical accuracy, and even basic brainstorming: unless an assignment
specifically requests it, you do not need to offer an explicit
acknowledgment. A question you should be asking is: did the computer
shape my conceptual understanding of this source or scholarly work? Is
my creative output inspired in a fundamental way by the AI? In a sense,
these quandaries are not new: if you got your idea from somewhere else,
you need to cite your source, and there have always been edge cases.
When in doubt, err on the side of transparency.</p>
<p>Your instructor is bound by these same principles when preparing
course material and offering feedback. I may use LLM assistance to help
format slides and to reconfigure the presentation of my feedback.
However, I will never feed any of your material into an LLM not <a
href="https://www.technology.pitt.edu/ai">approved for broad use by
Pitt</a> (i.e., to avoid privacy concerns); the content and phrasing of
all feedback will always come directly from me; and I will never use an
LLM to determine, or even suggest, a grade.</p>
<h2 id="llms-as-assistants-for-learning-history">LLMs as Assistants for
Learning History</h2>
<p>The following are some legitimate use cases (and words of caution)
for using AI in the field of history:</p>
<ul>
<li><em>Summarize a book or article</em>: LLMs are very effective at
this task (and the library e-reader already does this automatically). In
the face of time constraints, we have always been skimming and
“extracting” information from texts without reading: now we can do it
even better, and doing so is not “cheating.”
<ul>
<li><em>Caution</em>: LLMs are not as effective at noticing when a
detail not explicitly tied to the theme or thesis of a work matters. In
history especially, the details still matter, and those insights must
come from you: close reading still matters.</li>
</ul></li>
<li><em>Identify stylistic / grammatical / syntactical errors in an
essay</em>: The LLMs can identify the ways your writing is different or
similar to a massive body of published work, which <em>often</em>
equates to spotting legitimate errors. You can learn from this tool, so
use it.
<ul>
<li><em>Caution</em>: Remember that you can ask an interactive chatbot
for further explanation of a suggestion. If you are blindly adopting
writing suggestions without learning the underlying principle, you will
reproduce errors.</li>
</ul></li>
<li><em>Help me develop a coding tool</em>: With AI</li>
</ul>
<div class="date-stamp">Updated on August 16, 2025</div>
</body>
</html>
